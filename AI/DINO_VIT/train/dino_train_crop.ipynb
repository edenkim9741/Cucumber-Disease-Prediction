{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e5fd2e-4133-431f-bcfc-408c5e390b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading configuration and preparing dataset...\n",
      "--> Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import torchvision.transforms.functional as TF\n",
    "import time # 시간 측정을 위해 import\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. 설정 로드 및 준비\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"1. Loading configuration and preparing dataset...\")\n",
    "try:\n",
    "    with open(\"dino_train_crop.yaml\", 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: config.yaml 파일을 찾을 수 없습니다. 파일을 생성해주세요.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "DATA_PATH = config['data_path']\n",
    "MODEL_REPO = config['model_repo']\n",
    "MODEL_NAME = config['model_name']\n",
    "NUM_CLASSES = config['num_classes']\n",
    "FREEZE_BACKBONE = config['freeze_backbone']\n",
    "EPOCHS = config['epochs']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "DEVICE = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--> Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdb3801-f708-4150-a3b9-cbcf61c25005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Found 28315 training images and 5662 validation images.\n",
      "--> Classes: ['downy', 'healthy', 'powdery']\n"
     ]
    }
   ],
   "source": [
    "# --- 데이터 전처리 및 데이터로더  ---\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((224, 224)), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'train'), data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'validation'), data_transforms['validation'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(f\"--> Found {len(train_dataset)} training images and {len(val_dataset)} validation images.\")\n",
    "print(f\"--> Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046f371c-9bcd-48c7-bc41-c1b760a29d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Loading official DINOv2 model 'dinov2_vits14' from torch.hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Backbone is frozen. Only the classifier head will be trained.\n",
      "--> Model loaded and classifier head replaced successfully.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 2. DINOv2 모델 정의 (torch.hub 사용)\n",
    "# -----------------------------------\n",
    "\n",
    "print(f\"\\n2. Loading official DINOv2 model '{MODEL_NAME}' from torch.hub...\")\n",
    "try:\n",
    "    model = torch.hub.load(MODEL_REPO, MODEL_NAME, pretrained=True)\n",
    "    \n",
    "    if FREEZE_BACKBONE:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"--> Backbone is frozen. Only the classifier head will be trained.\")\n",
    "\n",
    "    # --- ✅ 코드 수정 부분 ---\n",
    "    # ViT-Small의 특징 벡터 크기는 384로 고정되어 있습니다.\n",
    "    num_features = 384 \n",
    "    # 기존의 model.head를 우리의 분류기로 완전히 교체합니다.\n",
    "    model.head = nn.Linear(num_features, NUM_CLASSES) \n",
    "    # --- ✅ 수정 완료 ---\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"--> Model loaded and classifier head replaced successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: An unexpected error occurred during model setup.\")\n",
    "    print(f\"--> Original Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a4be06-83ea-49c0-bdf4-4362e18591a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Starting the training process...\n",
      "Epoch 01/20 | Train | [====================] 100%\n",
      "Epoch 01/20 | Time: 12:27 | Train Loss: 0.1401 Acc: 0.9551 | Val Loss: 0.0626 Acc: 0.9820\n",
      "Epoch 02/20 | Train | [====================] 100%\n",
      "Epoch 02/20 | Time: 12:09 | Train Loss: 0.0561 Acc: 0.9834 | Val Loss: 0.0506 Acc: 0.9825\n",
      "Epoch 03/20 | Train | [====================] 100%\n",
      "Epoch 03/20 | Time: 12:08 | Train Loss: 0.0424 Acc: 0.9872 | Val Loss: 0.0357 Acc: 0.9892\n",
      "Epoch 04/20 | Train | [====================] 100%\n",
      "Epoch 04/20 | Time: 12:05 | Train Loss: 0.0360 Acc: 0.9889 | Val Loss: 0.0280 Acc: 0.9921\n",
      "Epoch 05/20 | Train | [====================] 100%\n",
      "Epoch 05/20 | Time: 12:12 | Train Loss: 0.0307 Acc: 0.9908 | Val Loss: 0.0261 Acc: 0.9929\n",
      "Epoch 06/20 | Train | [====================] 100%\n",
      "Epoch 06/20 | Time: 12:09 | Train Loss: 0.0279 Acc: 0.9913 | Val Loss: 0.0232 Acc: 0.9929\n",
      "Epoch 07/20 | Train | [====================] 100%\n",
      "Epoch 07/20 | Time: 12:13 | Train Loss: 0.0250 Acc: 0.9919 | Val Loss: 0.0226 Acc: 0.9931\n",
      "Epoch 08/20 | Train | [====================] 100%\n",
      "Epoch 08/20 | Time: 12:09 | Train Loss: 0.0235 Acc: 0.9929 | Val Loss: 0.0208 Acc: 0.9935\n",
      "Epoch 09/20 | Train | [====================] 100%\n",
      "Epoch 09/20 | Time: 12:11 | Train Loss: 0.0221 Acc: 0.9929 | Val Loss: 0.0188 Acc: 0.9943\n",
      "Epoch 10/20 | Train | [====================] 100%\n",
      "Epoch 10/20 | Time: 12:14 | Train Loss: 0.0210 Acc: 0.9934 | Val Loss: 0.0175 Acc: 0.9952\n",
      "Epoch 11/20 | Train | [====================] 100%\n",
      "Epoch 11/20 | Time: 12:06 | Train Loss: 0.0194 Acc: 0.9941 | Val Loss: 0.0178 Acc: 0.9942\n",
      "Epoch 12/20 | Train | [====================] 100%\n",
      "Epoch 12/20 | Time: 12:10 | Train Loss: 0.0185 Acc: 0.9940 | Val Loss: 0.0241 Acc: 0.9921\n",
      "Epoch 13/20 | Train | [====================] 100%\n",
      "Epoch 13/20 | Time: 12:07 | Train Loss: 0.0181 Acc: 0.9947 | Val Loss: 0.0156 Acc: 0.9958\n",
      "Epoch 14/20 | Train | [====================] 100%\n",
      "Epoch 14/20 | Time: 12:08 | Train Loss: 0.0169 Acc: 0.9945 | Val Loss: 0.0178 Acc: 0.9936\n",
      "Epoch 15/20 | Train | [====================] 100%\n",
      "Epoch 15/20 | Time: 12:11 | Train Loss: 0.0161 Acc: 0.9950 | Val Loss: 0.0155 Acc: 0.9954\n",
      "Epoch 16/20 | Train | [====================] 100%\n",
      "Epoch 16/20 | Time: 12:15 | Train Loss: 0.0154 Acc: 0.9952 | Val Loss: 0.0157 Acc: 0.9952\n",
      "Epoch 17/20 | Train | [====================] 100%\n",
      "Epoch 17/20 | Time: 12:09 | Train Loss: 0.0151 Acc: 0.9951 | Val Loss: 0.0162 Acc: 0.9947\n",
      "Epoch 18/20 | Train | [====================] 100%\n",
      "Epoch 18/20 | Time: 12:17 | Train Loss: 0.0146 Acc: 0.9952 | Val Loss: 0.0152 Acc: 0.9952\n",
      "Epoch 19/20 | Train | [====================] 100%\n",
      "Epoch 19/20 | Time: 12:15 | Train Loss: 0.0147 Acc: 0.9956 | Val Loss: 0.0177 Acc: 0.9942\n",
      "Epoch 20/20 | Train | [====================] 100%\n",
      "Epoch 20/20 | Time: 12:13 | Train Loss: 0.0143 Acc: 0.9955 | Val Loss: 0.0165 Acc: 0.9947\n",
      "\n",
      "Training complete!\n",
      "Model saved to dinov2_crop.pth\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# 3. 학습 (Training)\n",
    "# ----------------------------------\n",
    "\n",
    "print(\"\\n3. Starting the training process...\")\n",
    "best_val_acc = 0.0\n",
    "best_loss = 0.0\n",
    "# 손실 함수와 옵티마이저 정의 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "# 총 배치 수 미리 계산 (진행률 표시용)\n",
    "total_batches = len(train_loader)\n",
    "gauge_step = total_batches // 20 # 약 5%마다 게이지를 업데이트하기 위한 스텝\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- 에포크 시작 시간 기록 ---\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # --- 학습 단계 --\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # enumerate를 사용하여 배치 인덱스를 가져옴\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # --- 진행 게이지 출력 ---\n",
    "        progress = (batch_idx + 1) / total_batches\n",
    "        gauge_bar = '=' * int(progress * 20)\n",
    "        sys.stdout.write(f\"\\rEpoch {epoch+1:02d}/{EPOCHS} | Train | [{'%-20s' % gauge_bar}] {progress:.0%}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    # 게이지 줄바꿈 처리\n",
    "    print()\n",
    "\n",
    "    # --- 검증 단계 --\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    val_epoch_loss = val_loss / len(val_dataset)\n",
    "    val_epoch_acc = val_corrects.double() / len(val_dataset)\n",
    "\n",
    "    # --- 에포크 종료 시간 기록 및 출력 ---\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    # 분, 초로 변환\n",
    "    epoch_mins, epoch_secs = divmod(epoch_duration, 60)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "        f\"Time: {int(epoch_mins):02d}:{int(epoch_secs):02d} | \"\n",
    "        f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\"\n",
    "    )\n",
    "    if val_epoch_acc > best_val_acc or (val_epoch_acc == best_val_acc and best_loss > val_epoch_loss):\n",
    "        best_val_acc = val_epoch_acc\n",
    "        best_loss = val_epoch_loss\n",
    "        torch.save(model.state_dict(), \"dinov2_crop.pth\")\n",
    "        \n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"Model saved to dinov2_crop.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fed507-1e5b-4a6b-9c82-275bca08cdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra",
   "language": "python",
   "name": "ultra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

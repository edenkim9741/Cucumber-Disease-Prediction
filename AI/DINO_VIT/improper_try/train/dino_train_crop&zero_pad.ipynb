{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e5fd2e-4133-431f-bcfc-408c5e390b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading configuration and preparing dataset...\n",
      "--> Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import torchvision.transforms.functional as TF\n",
    "import time # 시간 측정을 위해 import\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. 설정 로드 및 준비\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"1. Loading configuration and preparing dataset...\")\n",
    "try:\n",
    "    with open(\"dino_train_crop.yaml\", 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: config.yaml 파일을 찾을 수 없습니다. 파일을 생성해주세요.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "DATA_PATH = config['data_path']\n",
    "MODEL_REPO = config['model_repo']\n",
    "MODEL_NAME = config['model_name']\n",
    "NUM_CLASSES = config['num_classes']\n",
    "FREEZE_BACKBONE = config['freeze_backbone']\n",
    "EPOCHS = config['epochs']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "LEARNING_RATE = config['learning_rate']\n",
    "DEVICE = torch.device(config['device'] if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--> Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b865d7-43c3-4a2f-b781-c0027cefb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop된 객체 전체가 224 x 224 안에 들어가도록 변환하는 함수들\n",
    "def resize_by_long_edge(img, size=224):\n",
    "    \"\"\" 긴 변을 기준으로 비율을 유지하며 리사이즈하는 함수 \"\"\"\n",
    "    w, h = img.size\n",
    "    if w > h:\n",
    "        new_w = size\n",
    "        new_h = int(h * (size / w))\n",
    "    else:\n",
    "        new_h = size\n",
    "        new_w = int(w * (size / h))\n",
    "    return img.resize((new_w, new_h))\n",
    "\n",
    "# 패딩을 추가하는 커스텀 변환 함수\n",
    "def pad_to_square(img):\n",
    "    w, h = img.size\n",
    "    max_wh = 224 # 최종 크기를 224로 고정\n",
    "    hp = (max_wh - w) // 2\n",
    "    vp = (max_wh - h) // 2\n",
    "    padding = (hp, vp, max_wh - w - hp, max_wh - h - vp) # 정확한 패딩 계산\n",
    "    return TF.pad(img, padding, 0, 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdb3801-f708-4150-a3b9-cbcf61c25005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Found 28315 training images and 5662 validation images.\n",
      "--> Classes: ['downy', 'healthy', 'powdery']\n"
     ]
    }
   ],
   "source": [
    "# --- 데이터 전처리 및 데이터로더  ---\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Lambda(resize_by_long_edge), transforms.Lambda(pad_to_square), transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'train'), data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_PATH, 'validation'), data_transforms['validation'])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(f\"--> Found {len(train_dataset)} training images and {len(val_dataset)} validation images.\")\n",
    "print(f\"--> Classes: {train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046f371c-9bcd-48c7-bc41-c1b760a29d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Loading official DINOv2 model 'dinov2_vits14' from torch.hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\51100/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Backbone is frozen. Only the classifier head will be trained.\n",
      "--> Model loaded and classifier head replaced successfully.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 2. DINOv2 모델 정의 (torch.hub 사용)\n",
    "# -----------------------------------\n",
    "\n",
    "print(f\"\\n2. Loading official DINOv2 model '{MODEL_NAME}' from torch.hub...\")\n",
    "try:\n",
    "    model = torch.hub.load(MODEL_REPO, MODEL_NAME, pretrained=True)\n",
    "    \n",
    "    if FREEZE_BACKBONE:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"--> Backbone is frozen. Only the classifier head will be trained.\")\n",
    "\n",
    "    # --- ✅ 코드 수정 부분 ---\n",
    "    # ViT-Small의 특징 벡터 크기는 384로 고정되어 있습니다.\n",
    "    num_features = 384 \n",
    "    # 기존의 model.head를 우리의 분류기로 완전히 교체합니다.\n",
    "    model.head = nn.Linear(num_features, NUM_CLASSES) \n",
    "    # --- ✅ 수정 완료 ---\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    print(\"--> Model loaded and classifier head replaced successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: An unexpected error occurred during model setup.\")\n",
    "    print(f\"--> Original Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a4be06-83ea-49c0-bdf4-4362e18591a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Starting the training process...\n",
      "Epoch 01/20 | Train | [====================] 100%\n",
      "Epoch 01/20 | Time: 12:43 | Train Loss: 0.1781 Acc: 0.9412 | Val Loss: 0.0790 Acc: 0.9779\n",
      "Epoch 02/20 | Train | [====================] 100%\n",
      "Epoch 02/20 | Time: 12:54 | Train Loss: 0.0912 Acc: 0.9711 | Val Loss: 0.0602 Acc: 0.9823\n",
      "Epoch 03/20 | Train | [====================] 100%\n",
      "Epoch 03/20 | Time: 12:44 | Train Loss: 0.0747 Acc: 0.9764 | Val Loss: 0.0513 Acc: 0.9846\n",
      "Epoch 04/20 | Train | [====================] 100%\n",
      "Epoch 04/20 | Time: 12:43 | Train Loss: 0.0669 Acc: 0.9791 | Val Loss: 0.0504 Acc: 0.9839\n",
      "Epoch 05/20 | Train | [====================] 100%\n",
      "Epoch 05/20 | Time: 12:47 | Train Loss: 0.0624 Acc: 0.9801 | Val Loss: 0.0444 Acc: 0.9866\n",
      "Epoch 06/20 | Train | [====================] 100%\n",
      "Epoch 06/20 | Time: 12:40 | Train Loss: 0.0561 Acc: 0.9822 | Val Loss: 0.0485 Acc: 0.9855\n",
      "Epoch 07/20 | Train | [====================] 100%\n",
      "Epoch 07/20 | Time: 12:49 | Train Loss: 0.0559 Acc: 0.9817 | Val Loss: 0.0392 Acc: 0.9875\n",
      "Epoch 08/20 | Train | [====================] 100%\n",
      "Epoch 08/20 | Time: 12:45 | Train Loss: 0.0559 Acc: 0.9823 | Val Loss: 0.0349 Acc: 0.9890\n",
      "Epoch 09/20 | Train | [====================] 100%\n",
      "Epoch 09/20 | Time: 12:43 | Train Loss: 0.0538 Acc: 0.9817 | Val Loss: 0.0450 Acc: 0.9843\n",
      "Epoch 10/20 | Train | [====================] 100%\n",
      "Epoch 10/20 | Time: 12:50 | Train Loss: 0.0521 Acc: 0.9824 | Val Loss: 0.0492 Acc: 0.9820\n",
      "Epoch 11/20 | Train | [====================] 100%\n",
      "Epoch 11/20 | Time: 12:55 | Train Loss: 0.0522 Acc: 0.9827 | Val Loss: 0.0399 Acc: 0.9862\n",
      "Epoch 12/20 | Train | [====================] 100%\n",
      "Epoch 12/20 | Time: 12:46 | Train Loss: 0.0505 Acc: 0.9841 | Val Loss: 0.0320 Acc: 0.9899\n",
      "Epoch 13/20 | Train | [====================] 100%\n",
      "Epoch 13/20 | Time: 12:31 | Train Loss: 0.0493 Acc: 0.9835 | Val Loss: 0.0413 Acc: 0.9853\n",
      "Epoch 14/20 | Train | [====================] 100%\n",
      "Epoch 14/20 | Time: 12:42 | Train Loss: 0.0491 Acc: 0.9840 | Val Loss: 0.0358 Acc: 0.9878\n",
      "Epoch 15/20 | Train | [====================] 100%\n",
      "Epoch 15/20 | Time: 12:49 | Train Loss: 0.0471 Acc: 0.9840 | Val Loss: 0.0301 Acc: 0.9903\n",
      "Epoch 16/20 | Train | [====================] 100%\n",
      "Epoch 16/20 | Time: 12:41 | Train Loss: 0.0470 Acc: 0.9848 | Val Loss: 0.0302 Acc: 0.9889\n",
      "Epoch 17/20 | Train | [====================] 100%\n",
      "Epoch 17/20 | Time: 12:46 | Train Loss: 0.0475 Acc: 0.9843 | Val Loss: 0.0319 Acc: 0.9887\n",
      "Epoch 18/20 | Train | [====================] 100%\n",
      "Epoch 18/20 | Time: 12:44 | Train Loss: 0.0461 Acc: 0.9853 | Val Loss: 0.0288 Acc: 0.9899\n",
      "Epoch 19/20 | Train | [====================] 100%\n",
      "Epoch 19/20 | Time: 12:40 | Train Loss: 0.0423 Acc: 0.9868 | Val Loss: 0.0387 Acc: 0.9873\n",
      "Epoch 20/20 | Train | [====================] 100%\n",
      "Epoch 20/20 | Time: 12:43 | Train Loss: 0.0469 Acc: 0.9841 | Val Loss: 0.0337 Acc: 0.9890\n",
      "\n",
      "Training complete!\n",
      "Model saved to dinov2_zeropad.pth\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------\n",
    "# 3. 학습 (Training)\n",
    "# ----------------------------------\n",
    "\n",
    "print(\"\\n3. Starting the training process...\")\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "# 총 배치 수 미리 계산 (진행률 표시용)\n",
    "total_batches = len(train_loader)\n",
    "gauge_step = total_batches // 20 # 약 5%마다 게이지를 업데이트하기 위한 스텝\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- 에포크 시작 시간 기록 ---\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # --- 학습 단계 --\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # enumerate를 사용하여 배치 인덱스를 가져옴\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # --- 진행 게이지 출력 ---\n",
    "        progress = (batch_idx + 1) / total_batches\n",
    "        gauge_bar = '=' * int(progress * 20)\n",
    "        sys.stdout.write(f\"\\rEpoch {epoch+1:02d}/{EPOCHS} | Train | [{'%-20s' % gauge_bar}] {progress:.0%}\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    # 게이지 줄바꿈 처리\n",
    "    print()\n",
    "\n",
    "    # --- 검증 단계 --\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    val_epoch_loss = val_loss / len(val_dataset)\n",
    "    val_epoch_acc = val_corrects.double() / len(val_dataset)\n",
    "\n",
    "    # --- 에포크 종료 시간 기록 및 출력 ---\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    # 분, 초로 변환\n",
    "    epoch_mins, epoch_secs = divmod(epoch_duration, 60)\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "        f\"Time: {int(epoch_mins):02d}:{int(epoch_secs):02d} | \"\n",
    "        f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "torch.save(model.state_dict(), 'dinov2_zeropad.pth')\n",
    "print(\"Model saved to dinov2_zeropad.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fed507-1e5b-4a6b-9c82-275bca08cdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra",
   "language": "python",
   "name": "ultra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
